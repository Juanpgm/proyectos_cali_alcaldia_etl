"""
Extractor de procesos SECOP usando la API de datos abiertos
Filtrado por nit_entidad = 890399011 (Alcald√≠a de Cali) y referencias espec√≠ficas

Este m√≥dulo extrae datos del dataset de procesos de contrataci√≥n SECOP (p6dx-8zbt)
usando las referencias de proceso cargadas desde el archivo JSON.
"""

import pandas as pd
from sodapy import Socrata
import time
import logging
from datetime import datetime
from pathlib import Path
from tqdm import tqdm
import json

# Config de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('extraction_logs.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Constantes del SECOP
SECOP_DOMAIN = "www.datos.gov.co"
DATASET_ID = "p6dx-8zbt"  # ID del dataset de procesos de contrataci√≥n
NIT_ENTIDAD_CALI = "890399011"  # NIT de la Alcald√≠a de Cali
OUTPUT_DIR = Path("transformation_app/app_inputs/procesos_secop_input")
REFERENCIAS_JSON_PATH = Path("transformation_app/app_inputs/indice_procesos_emprestito/indice_procesos.json")
RECORDS_PER_REQUEST = 1000  # L√≠mite por request del API
REQUEST_TIMEOUT = 30  # Timeout en segundos para requests


class SecopProcessExtractor:
    """Extractor de procesos SECOP."""
    
    def __init__(self):
        """Inicializar el extractor."""
        self.client = None
        self.target_references = []
        self.setup_client()
        self.setup_output_directory()
        self.load_target_references()
        
    def setup_client(self):
        """Configurar cliente SECOP sin autenticaci√≥n."""
        try:
            # Cliente no autenticado para datos p√∫blicos con timeout personalizado
            self.client = Socrata(SECOP_DOMAIN, None, timeout=REQUEST_TIMEOUT)
            logger.info(f"‚úì Cliente SECOP configurado para dominio: {SECOP_DOMAIN}")
            logger.info(f"‚è±Ô∏è  Timeout configurado: {REQUEST_TIMEOUT} segundos")
            
        except Exception as e:
            logger.error(f"‚ùå Error configurando cliente SECOP: {e}")
            raise
    
    def setup_output_directory(self):
        """Crear directorio de salida si no existe."""
        try:
            OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
            logger.info(f"‚úì Directorio de salida configurado: {OUTPUT_DIR}")
            
        except Exception as e:
            logger.error(f"‚ùå Error creando directorio de salida: {e}")
            raise
    
    def load_target_references(self):
        """Cargar las referencias de proceso desde el archivo JSON."""
        try:
            if not REFERENCIAS_JSON_PATH.exists():
                logger.error(f"‚ùå No se encontr√≥ el archivo de referencias: {REFERENCIAS_JSON_PATH}")
                raise FileNotFoundError(f"Archivo no encontrado: {REFERENCIAS_JSON_PATH}")
            
            with open(REFERENCIAS_JSON_PATH, 'r', encoding='utf-8') as f:
                referencias_data = json.load(f)
            
            # Extraer referencias de proceso de los arrays, limpiando espacios
            self.target_references = []
            for item in referencias_data:
                if 'referencia_proceso' in item and isinstance(item['referencia_proceso'], list):
                    for ref in item['referencia_proceso']:
                        if ref and ref.strip():  # Solo referencias no vac√≠as
                            self.target_references.append(ref.strip())
            
            # Eliminar duplicados manteniendo el orden
            self.target_references = list(dict.fromkeys(self.target_references))
            
            logger.info(f"‚úì Cargadas {len(self.target_references)} referencias de proceso objetivo")
            logger.info(f"üìã Primeras 5 referencias: {self.target_references[:5]}")
            
        except Exception as e:
            logger.error(f"‚ùå Error cargando referencias objetivo: {e}")
            raise
    
    def extract_processes_by_references(self):
        """Extraer procesos espec√≠ficos basados en las referencias cargadas."""
        try:
            logger.info(f"üîç Iniciando extracci√≥n de procesos SECOP para NIT: {NIT_ENTIDAD_CALI}")
            logger.info(f"üéØ Buscando {len(self.target_references)} referencias espec√≠ficas")
            
            all_processes = []
            found_references = []
            not_found_references = []
            
            # Configurar barra de progreso
            progress_bar = tqdm(
                self.target_references,
                desc="üîç Buscando procesos",
                unit="ref"
            )
            
            for ref_proceso in progress_bar:
                try:
                    # Actualizar descripci√≥n de la barra
                    progress_bar.set_postfix({
                        'Ref': ref_proceso[:20] + "..." if len(ref_proceso) > 20 else ref_proceso,
                        'Encontrados': len(found_references)
                    })
                    
                    logger.debug(f"üîç Buscando proceso: {ref_proceso}")
                    
                    # Construir filtros: NIT + referencia espec√≠fica
                    where_clause = f"nit_entidad='{NIT_ENTIDAD_CALI}' AND referencia_del_proceso='{ref_proceso}'"
                    
                    # Realizar consulta para esta referencia espec√≠fica
                    results = self.client.get(
                        DATASET_ID,
                        where=where_clause,
                        limit=RECORDS_PER_REQUEST  # Deber√≠a ser suficiente para una referencia
                    )
                    
                    if results:
                        # Agregar identificador de fuente a cada proceso
                        for process in results:
                            process['data_source'] = 'procesos_secop'
                        
                        all_processes.extend(results)
                        found_references.append(ref_proceso)
                        logger.info(f"‚úì Encontrado: {ref_proceso} ({len(results)} registros)")
                    else:
                        not_found_references.append(ref_proceso)
                        logger.debug(f"‚ö†Ô∏è No encontrado: {ref_proceso}")
                    
                    # Pausa para no sobrecargar el API
                    time.sleep(0.3)
                    
                except Exception as e:
                    logger.warning(f"‚ùå Error buscando {ref_proceso}: {e}")
                    not_found_references.append(ref_proceso)
                    continue
            
            progress_bar.close()
            
            # Mostrar estad√≠sticas finales
            logger.info(f"üéâ Extracci√≥n completada:")
            logger.info(f"   ‚úÖ Referencias encontradas: {len(found_references)}")
            logger.info(f"   ‚ùå Referencias no encontradas: {len(not_found_references)}")
            logger.info(f"   üìä Total de procesos extra√≠dos: {len(all_processes)}")
            
            if not_found_references:
                logger.info("‚ùå Referencias no encontradas:")
                for ref in not_found_references[:10]:  # Mostrar solo las primeras 10
                    logger.info(f"   - {ref}")
                if len(not_found_references) > 10:
                    logger.info(f"   ... y {len(not_found_references) - 10} m√°s")
            
            return all_processes
            
        except Exception as e:
            logger.error(f"‚ùå Error en extracci√≥n de procesos: {e}")
            raise
    

    
    def clean_data_for_excel(self, df):
        """Limpiar datos para evitar errores de caracteres ilegales en Excel."""
        try:
            logger.info("üßπ Limpiando datos para Excel...")
            df_clean = df.copy()
            
            # Funci√≥n para limpiar strings
            def clean_string(text):
                if pd.isna(text) or not isinstance(text, str):
                    return text
                
                # Remover caracteres de control y caracteres problem√°ticos
                import re
                # Remover caracteres de control (excepto tab, newline, carriage return)
                text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]', '', text)
                
                # Reemplazar caracteres problem√°ticos espec√≠ficos
                problematic_chars = {
                    '‚òª': '',
                    '‚ô†': '',
                    '‚ô£': '',
                    '‚ô•': '',
                    '‚ô¶': '',
                    '\x01': '',
                    '\x02': '',
                    '\x03': '',
                    '\x04': '',
                    '\x05': '',
                    '\x06': '',
                    '\x07': '',
                    '\x08': '',
                }
                
                for char, replacement in problematic_chars.items():
                    text = text.replace(char, replacement)
                
                # Limpiar espacios m√∫ltiples y saltos de l√≠nea
                text = re.sub(r'\s+', ' ', text).strip()
                
                return text
            
            # Aplicar limpieza a todas las columnas de texto
            for column in df_clean.columns:
                if df_clean[column].dtype == 'object':
                    df_clean[column] = df_clean[column].apply(clean_string)
            
            logger.info("‚úÖ Datos limpiados exitosamente")
            return df_clean
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Error limpiando datos: {e}, continuando con datos originales")
            return df

    def save_data_to_files(self, processes_data):
        """Guardar procesos en archivos."""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            results = {}
            
            # Guardar procesos SECOP si hay datos
            if processes_data:
                logger.info("üíæ Guardando datos de procesos SECOP...")
                df_processes = pd.DataFrame.from_records(processes_data)
                
                # Agregar identificador de fuente
                df_processes['data_source'] = 'procesos_secop'
                df_processes_clean = self.clean_data_for_excel(df_processes)
                
                # Guardar procesos en JSON
                processes_filename = "procesos_secop_emprestito.json"
                processes_path = OUTPUT_DIR / processes_filename
                
                data_list = df_processes_clean.to_dict('records')
                cleaned_data = self.clean_data_for_json(data_list)
                
                with open(processes_path, 'w', encoding='utf-8') as f:
                    json.dump(cleaned_data, f, ensure_ascii=False, indent=2)
                
                logger.info(f"‚úÖ Procesos guardados: {processes_path}")
                results['processes'] = {
                    "json_path": processes_path,
                    "records_count": len(df_processes)
                }
                
                # Mostrar resumen de procesos
                logger.info(f"\nüìä RESUMEN PROCESOS SECOP: {len(df_processes)} registros")
                self.show_data_summary(df_processes)
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Error guardando archivos: {e}")
            raise
    
    def clean_data_for_json(self, data_list):
        """Limpiar datos para formato JSON."""
        cleaned_data = []
        for record in data_list:
            cleaned_record = {}
            for key, value in record.items():
                if pd.isna(value):
                    cleaned_record[key] = None
                elif isinstance(value, (pd.Timestamp, datetime)):
                    cleaned_record[key] = value.isoformat() if pd.notna(value) else None
                else:
                    cleaned_record[key] = value
            cleaned_data.append(cleaned_record)
        return cleaned_data
    
    def show_data_summary(self, df):
        """Mostrar resumen de los datos extra√≠dos."""
        try:
            logger.info("\n" + "="*60)
            logger.info("üìä RESUMEN DE DATOS EXTRA√çDOS")
            logger.info("="*60)
            logger.info(f"üìã Total de procesos: {len(df):,}")
            logger.info(f"üìä Total de columnas: {len(df.columns)}")
            
            # Mostrar informaci√≥n de fechas si est√° disponible
            date_columns = [col for col in df.columns if 'fecha' in col.lower()]
            if date_columns:
                logger.info(f"üìÖ Columnas de fecha encontradas: {date_columns}")
                
                for date_col in date_columns[:2]:  # Mostrar hasta 2 columnas de fecha
                    if not df[date_col].isna().all():
                        try:
                            df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                            min_date = df[date_col].min()
                            max_date = df[date_col].max()
                            logger.info(f"   üìÖ {date_col}: desde {min_date} hasta {max_date}")
                        except:
                            logger.debug(f"No se pudo procesar fecha en columna: {date_col}")
            
            # Mostrar algunas columnas importantes si existen
            important_columns = [
                'referencia_del_proceso', 'descripci_n_del_procedimiento', 'estado_del_procedimiento',
                'modalidad_de_contratacion', 'nombre_del_procedimiento', 'precio_base'
            ]
            
            available_important = [col for col in important_columns if col in df.columns]
            if available_important:
                logger.info(f"üìÑ Columnas importantes disponibles: {available_important}")
            
            # Estad√≠sticas de presupuesto si est√° disponible
            budget_columns = [col for col in df.columns if 'presupuesto' in col.lower() or 'valor' in col.lower()]
            if budget_columns:
                for budget_col in budget_columns[:1]:  # Solo el primero
                    try:
                        df[budget_col] = pd.to_numeric(df[budget_col], errors='coerce')
                        total_budget = df[budget_col].sum()
                        avg_budget = df[budget_col].mean()
                        if not pd.isna(total_budget) and total_budget > 0:
                            logger.info(f"üí∞ {budget_col} total: ${total_budget:,.2f}")
                            logger.info(f"üí∞ {budget_col} promedio: ${avg_budget:,.2f}")
                    except:
                        logger.debug(f"No se pudo calcular estad√≠sticas para: {budget_col}")
            
            # Mostrar estados de proceso si est√°n disponibles
            if 'estado_proceso' in df.columns:
                estados = df['estado_proceso'].value_counts()
                logger.info(f"üìä Estados de procesos encontrados:")
                for estado, count in estados.head(5).items():
                    logger.info(f"   - {estado}: {count}")
            
            logger.info("="*60)
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Error mostrando resumen: {e}")
    
    def run_extraction(self):
        """Ejecutar proceso completo de extracci√≥n de procesos."""
        try:
            start_time = datetime.now()
            logger.info(f"üöÄ Iniciando extracci√≥n de procesos SECOP - {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info("üìã Extrayendo datos de:")
            logger.info(f"   üîç Procesos SECOP (Dataset: {DATASET_ID})")
            
            # 1. Extraer procesos SECOP espec√≠ficos
            logger.info("\n" + "="*60)
            logger.info("üîç EXTRACCI√ìN DE PROCESOS SECOP")
            logger.info("="*60)
            processes = self.extract_processes_by_references()
            
            # 2. Guardar resultados
            logger.info("\n" + "="*60)
            logger.info("üíæ GUARDANDO RESULTADOS")
            logger.info("="*60)
            
            if processes:
                save_results = self.save_data_to_files(processes)
                
                # Calcular tiempo total
                end_time = datetime.now()
                duration = end_time - start_time
                
                # Mostrar resumen final
                logger.info("\n" + "="*80)
                logger.info("üéâ EXTRACCI√ìN COMPLETADA")
                logger.info("="*80)
                logger.info(f"‚è±Ô∏è  Tiempo total de extracci√≥n: {duration}")
                logger.info(f"üìÅ Archivos guardados en: {OUTPUT_DIR}")
                
                # Estad√≠sticas detalladas
                if 'processes' in save_results:
                    logger.info(f"üìÑ Procesos SECOP extra√≠dos: {save_results['processes']['records_count']:,}")
                
                # Listar archivos generados
                logger.info("\nüìÅ Archivos generados:")
                for key, result in save_results.items():
                    logger.info(f"   üìÑ {key.title().replace('_', ' ')}: {result['json_path'].name}")
                
                return save_results
                
            else:
                logger.warning("‚ö†Ô∏è  No se encontraron datos para extraer")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error en proceso de extracci√≥n: {e}")
            raise
        
        finally:
            # Cerrar cliente
            if self.client:
                self.client.close()
                logger.info("üîí Cliente SECOP cerrado")


def main():
    """Funci√≥n principal."""
    try:
        logger.info("="*80)
        logger.info("üèõÔ∏è  EXTRACTOR DE PROCESOS SECOP - ALCALD√çA DE CALI")
        logger.info("="*80)
        logger.info(f"üìç NIT de entidad: {NIT_ENTIDAD_CALI}")
        logger.info(f"üóÇÔ∏è  Dataset ID: {DATASET_ID}")
        logger.info(f"üìÇ Directorio de salida: {OUTPUT_DIR}")
        logger.info(f"üìã Archivo de referencias: {REFERENCIAS_JSON_PATH}")
        
        # Crear y ejecutar extractor
        extractor = SecopProcessExtractor()
        results = extractor.run_extraction()
        
        if results:
            logger.info("\n" + "="*50)
            logger.info("‚úÖ PROCESO COMPLETADO EXITOSAMENTE")
            logger.info("="*50)
            
            # Mostrar estad√≠sticas
            if 'processes' in results:
                logger.info(f"üìÑ Procesos SECOP extra√≠dos: {results['processes']['records_count']:,}")
                logger.info(f"üìÅ Archivo de procesos: {results['processes']['json_path'].name}")
            
            logger.info(f"üìÇ Ubicaci√≥n: {OUTPUT_DIR}")
        else:
            logger.warning("‚ö†Ô∏è  No se generaron archivos de salida")
            
    except Exception as e:
        logger.error(f"‚ùå Error cr√≠tico en main: {e}")
        raise


if __name__ == "__main__":
    main()
