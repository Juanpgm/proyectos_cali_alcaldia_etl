name: ETL Data Processing Automation

on:
  # Ejecuci√≥n autom√°tica diaria a las 2 AM UTC (10 PM hora de Cali)
  schedule:
    - cron: "0 2 * * *"

  # Trigger manual desde GitHub UI
  workflow_dispatch:
    inputs:
      data_types:
        description: 'Data types to process (comma-separated or "all")'
        required: false
        default: "all"
      clear_existing:
        description: "Clear existing data before loading"
        type: boolean
        required: false
        default: false
      force_extraction:
        description: "Force re-extraction even if recent data exists"
        type: boolean
        required: false
        default: false

  # Trigger on push to main branch (opcional - solo para testing)
  push:
    branches: [main]
    paths:
      - "extraction_app/**"
      - "transformation_app/**"
      - "load_app/**"
      - ".github/workflows/**"

env:
  PYTHON_VERSION: "3.12"
  TZ: "America/Bogota"

jobs:
  health-check:
    name: Health Check and Prerequisites
    runs-on: ubuntu-latest
    outputs:
      database_healthy: ${{ steps.db-check.outputs.healthy }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install core dependencies
        run: |
          pip install --upgrade pip
          pip install psycopg2-binary python-dotenv sqlalchemy

      - name: Test database connection
        id: db-check
        env:
          DATABASE_URL: ${{ secrets.RAILWAY_DATABASE_URL }}
        run: |
          python3 .github/scripts/test_connection.py

  data-extraction:
    name: Data Extraction
    runs-on: ubuntu-latest
    needs: health-check
    if: needs.health-check.outputs.database_healthy == 'true'

    strategy:
      matrix:
        extraction_type:
          - "dacp_sheets"
          - "emprestito_data"
          - "paa_dacp"
          - "unidades_proyecto"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Setup Chrome for Selenium
        uses: browser-actions/setup-chrome@latest
        if: matrix.extraction_type == 'dacp_sheets'

      - name: Run extraction - ${{ matrix.extraction_type }}
        env:
          FORCE_EXTRACTION: ${{ github.event.inputs.force_extraction || 'false' }}
        run: |
          case "${{ matrix.extraction_type }}" in
            "dacp_sheets")
              echo "üîÑ Extracting DACP contracting data..."
              python extraction_app/data_extraction_contracting_dacp_sheets.py
              ;;
            "emprestito_data")
              echo "üîÑ Extracting emprestito data..."
              python extraction_app/data_extraction_contratos_emprestito.py
              python extraction_app/data_extraction_procesos_emprestito.py
              ;;
            "paa_dacp")
              echo "üîÑ Extracting PAA DACP data..."
              python extraction_app/data_extraction_paa_dacp_sheet.py
              ;;
            "unidades_proyecto")
              echo "üîÑ Extracting unidades proyecto data..."
              python extraction_app/data_extraction_unidades_proyecto_equipamientos.py
              ;;
          esac

      - name: Upload extraction artifacts
        uses: actions/upload-artifact@v4
        with:
          name: extraction-results-${{ matrix.extraction_type }}
          path: |
            extraction_app/outputs/
            transformation_app/app_inputs/
          retention-days: 7

  data-transformation:
    name: Data Transformation
    runs-on: ubuntu-latest
    needs: [health-check, data-extraction]
    if: needs.health-check.outputs.database_healthy == 'true'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download extraction artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: extraction-results-*
          merge-multiple: true

      - name: Run all transformations
        run: |
          echo "üîÑ Running data transformations..."

          echo "üìä Transforming contracts DACP..."
          python transformation_app/data_transformation_contracts_dacp.py

          echo "üìä Transforming SECOP contracts..."
          python transformation_app/data_transformation_contratos_secop.py

          echo "üìä Transforming budget execution..."
          python transformation_app/data_transformation_ejecucion_presupuestal.py

          echo "üìä Transforming PAA DACP..."
          python transformation_app/data_transformation_paa_dacp.py

          echo "üìä Transforming SECOP processes..."
          python transformation_app/data_transformation_procesos_secop.py

          echo "üìä Transforming project units..."
          python transformation_app/data_transformation_unidades_proyecto.py

          echo "üìä Transforming gravity centers..."
          python transformation_app/data_trasnformation_centros_gravedad.py

          echo "‚úÖ All transformations completed"

      - name: Upload transformation artifacts
        uses: actions/upload-artifact@v4
        with:
          name: transformation-results
          path: transformation_app/app_outputs/
          retention-days: 7

  data-loading:
    name: Data Loading to Railway PostgreSQL
    runs-on: ubuntu-latest
    needs: [health-check, data-transformation]
    if: needs.health-check.outputs.database_healthy == 'true'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download transformation artifacts
        uses: actions/download-artifact@v4
        with:
          name: transformation-results
          path: transformation_app/app_outputs/

      - name: Load data to Railway PostgreSQL
        env:
          DATABASE_URL: ${{ secrets.RAILWAY_DATABASE_URL }}
        run: |
          echo "üöÇ Loading data to Railway PostgreSQL..."

          DATA_TYPES="${{ github.event.inputs.data_types || 'all' }}"
          CLEAR_EXISTING="${{ github.event.inputs.clear_existing || 'false' }}"

          if [ "$CLEAR_EXISTING" = "true" ]; then
            echo "üóëÔ∏è Clearing existing data..."
            python load_app/bulk_load_data.py --data-type "$DATA_TYPES" --clear
          else
            echo "üì§ Loading data (append mode)..."
            python load_app/bulk_load_data.py --data-type "$DATA_TYPES"
          fi

          echo "‚úÖ Data loading completed"

      - name: Verify data loading
        env:
          DATABASE_URL: ${{ secrets.RAILWAY_DATABASE_URL }}
        run: |
          echo "üîç Verifying data in Railway database..."
          python -c "
          import os
          import psycopg2
          from datetime import datetime

          conn = psycopg2.connect(os.getenv('DATABASE_URL'))
          cursor = conn.cursor()

          # Check table record counts
          tables = [
              'unidades_proyecto',
              'datos_caracteristicos_proyectos',
              'ejecucion_presupuestal',
              'movimientos_presupuestales',
              'procesos_contratacion_dacp',
              'ordenes_compra_dacp',
              'paa_dacp',
              'emp_paa_dacp'
          ]

          print(f'üìä Database verification - {datetime.now()}')
          print('=' * 50)

          total_records = 0
          for table in tables:
              try:
                  cursor.execute(f'SELECT COUNT(*) FROM {table};')
                  count = cursor.fetchone()[0]
                  total_records += count
                  status = '‚úÖ' if count > 0 else '‚ö†Ô∏è'
                  print(f'{status} {table}: {count:,} records')
              except Exception as e:
                  print(f'‚ùå {table}: Error - {e}')

          print('=' * 50)
          print(f'üìà Total records across all tables: {total_records:,}')

          cursor.close()
          conn.close()
          "

  notification:
    name: Send Completion Notification
    runs-on: ubuntu-latest
    needs: [health-check, data-loading]
    if: always()

    steps:
      - name: Log completion status
        run: |
          if [ "${{ needs.health-check.result }}" = "success" ] && [ "${{ needs.data-loading.result }}" = "success" ]; then
            echo "‚úÖ ETL process completed successfully"
          else
            echo "‚ùå ETL process failed"
          fi
          echo "Timestamp: $(date)"
          echo "Trigger: ${{ github.event_name }}"
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "Manual parameters:"
            echo "  Data types: ${{ github.event.inputs.data_types || 'all' }}"
            echo "  Clear existing: ${{ github.event.inputs.clear_existing || 'false' }}"
            echo "  Force extraction: ${{ github.event.inputs.force_extraction || 'false' }}"
          fi
