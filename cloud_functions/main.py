"""
Cloud Function Principal: Pipeline ETL Serverless Completo
Ejecuta extracci√≥n, transformaci√≥n y carga a Firebase cada hora
Usa m√≥dulos espec√≠ficos para cada etapa del pipeline
"""

import functions_framework
from flask import jsonify
import os
import sys
import json
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Dict, Any

# Agregar paths para importar m√≥dulos del proyecto
# En Cloud Functions, los m√≥dulos est√°n en el mismo directorio
sys.path.insert(0, os.path.dirname(__file__))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'transformation_app'))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'load_app'))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'extraction_app'))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'utils'))


@functions_framework.http
def etl_pipeline_hourly(request):
    """
    HTTP Cloud Function para ejecutar pipeline ETL completo cada hora.
    Ejecuta: Extracci√≥n -> Transformaci√≥n -> Carga a Firebase
    
    Trigger:
    - Cloud Scheduler con cron: '0 * * * *' (cada hora desde medianoche)
    - HTTP POST/GET manual para testing
    
    Args:
        request (flask.Request): Request HTTP
        
    Returns:
        JSON con resultados de la operaci√≥n completa
    """
    result = {
        'success': False,
        'timestamp': datetime.now().isoformat(),
        'function': 'etl_pipeline_hourly',
        'pipeline_stages': {
            'extraction': {'success': False, 'records': 0},
            'transformation': {'success': False, 'records': 0},
            'load': {'success': False, 'records_uploaded': 0}
        },
        'errors': []
    }
    
    try:
        print("="*80)
        print("üöÄ INICIANDO PIPELINE ETL SERVERLESS COMPLETO")
        print(f"‚è∞ Hora de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80)
        
        # ========== ETAPA 1: EXTRACCI√ìN Y TRANSFORMACI√ìN ==========
        print("\n" + "="*80)
        print("üì• ETAPA 1 & 2: EXTRACCI√ìN Y TRANSFORMACI√ìN")
        print("="*80)
        
        try:
            # Importar funci√≥n de transformaci√≥n (incluye extracci√≥n integrada)
            from transformation_app.data_transformation_unidades_proyecto import transform_and_save_unidades_proyecto
            
            # Ejecutar transformaci√≥n (incluye extracci√≥n desde Google Drive)
            print("\nüîÑ Ejecutando extracci√≥n y transformaci√≥n...")
            gdf_result = transform_and_save_unidades_proyecto()
            
            if gdf_result is not None and len(gdf_result) > 0:
                result['pipeline_stages']['extraction']['success'] = True
                result['pipeline_stages']['extraction']['records'] = len(gdf_result)
                result['pipeline_stages']['transformation']['success'] = True
                result['pipeline_stages']['transformation']['records'] = len(gdf_result)
                
                print(f"\n‚úÖ Transformaci√≥n completada: {len(gdf_result)} registros")
            else:
                result['errors'].append("Transformaci√≥n no produjo datos v√°lidos")
                return jsonify(result), 500
                
        except Exception as e:
            print(f"\n‚ùå Error en extracci√≥n/transformaci√≥n: {e}")
            import traceback
            traceback.print_exc()
            result['errors'].append(f"Extraction/Transformation error: {str(e)}")
            return jsonify(result), 500
        
        # ========== ETAPA 3: CARGA A FIREBASE ==========
        print("\n" + "="*80)
        print("üì§ ETAPA 3: CARGA A FIREBASE")
        print("="*80)
        
        try:
            # Importar funci√≥n de carga espec√≠fica
            from load_app.data_loading_unidades_proyecto import load_unidades_proyecto_to_firebase
            
            # Buscar el archivo GeoJSON generado por transformaci√≥n
            transformation_output_dir = Path(__file__).parent.parent / 'transformation_app' / 'app_outputs' / 'unidades_proyecto_outputs'
            geojson_file = transformation_output_dir / 'unidades_proyecto.geojson'
            
            if not geojson_file.exists():
                # Buscar en app_outputs (ruta alternativa)
                alt_output_dir = Path(__file__).parent.parent / 'app_outputs'
                geojson_file = alt_output_dir / 'unidades_proyecto_transformed.geojson'
            
            if not geojson_file.exists():
                result['errors'].append(f"Archivo GeoJSON no encontrado en rutas esperadas")
                return jsonify(result), 500
            
            print(f"\nüìÇ Usando archivo: {geojson_file}")
            
            # Ejecutar carga a Firebase con actualizaci√≥n selectiva
            print("\nüî• Cargando a Firebase con actualizaciones selectivas por upid...")
            load_success = load_unidades_proyecto_to_firebase(
                input_file=str(geojson_file),
                collection_name="unidades_proyecto",
                batch_size=100
            )
            
            if load_success:
                result['pipeline_stages']['load']['success'] = True
                result['pipeline_stages']['load']['records_uploaded'] = len(gdf_result)
                result['success'] = True
                print("\n‚úÖ Carga a Firebase completada exitosamente")
            else:
                result['errors'].append("Carga a Firebase fall√≥")
                return jsonify(result), 500
                
        except Exception as e:
            print(f"\n‚ùå Error en carga a Firebase: {e}")
            import traceback
            traceback.print_exc()
            result['errors'].append(f"Firebase load error: {str(e)}")
            return jsonify(result), 500
        
        # ========== RESUMEN FINAL ==========
        print("\n" + "="*80)
        print("üìä RESUMEN DEL PIPELINE ETL")
        print("="*80)
        print(f"‚úÖ Extracci√≥n: {result['pipeline_stages']['extraction']['records']} registros")
        print(f"‚úÖ Transformaci√≥n: {result['pipeline_stages']['transformation']['records']} registros")
        print(f"‚úÖ Carga Firebase: {result['pipeline_stages']['load']['records_uploaded']} registros")
        print("="*80)
        print("üéâ PIPELINE ETL COMPLETADO EXITOSAMENTE")
        print("="*80)
        
        return jsonify(result), 200
        
    except Exception as e:
        print(f"\n‚ùå Error general en pipeline: {e}")
        import traceback
        traceback.print_exc()
        
        result['errors'].append(str(e))
        return jsonify(result), 500


@functions_framework.http
def manual_trigger(request):
    """
    Trigger manual para ejecutar el pipeline ETL bajo demanda.
    
    Uso:
        POST/GET a la URL de la funci√≥n para ejecutar pipeline completo
    
    Returns:
        JSON con resultado de la operaci√≥n
    """
    try:
        print("üéØ Trigger manual del pipeline ETL iniciado")
        print(f"‚è∞ Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # Ejecutar pipeline completo
        return etl_pipeline_hourly(request)
        
    except Exception as e:
        print(f"‚ùå Error en trigger manual: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


# ========== NOTIFICATION TRIGGERS ==========
# These functions are intended to be deployed as Background Cloud Functions (Firestore Triggers)
# They are not HTTP functions.

from notifications import on_unidades_proyecto_write, on_contrato_write
