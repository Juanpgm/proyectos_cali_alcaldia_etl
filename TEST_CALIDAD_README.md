# Script de Testing de Calidad de Datos ETL

## ğŸ“‹ DescripciÃ³n

Script completo de testing que verifica la calidad de los datos transformados por la ETL, garantizando que cumplan con las reglas de negocio y los estÃ¡ndares de calidad establecidos.

## âœ… Pruebas Implementadas

### 1. Congruencia entre `estado` y `avance_obra`

Verifica que la variable `estado` sea congruente con el valor de `avance_obra`:

- **Regla CrÃ­tica**: Si `avance_obra` = 0, entonces `estado` DEBE ser "En Alistamiento"
- **Advertencia**: Si `avance_obra` > 0 pero `estado` = "En Alistamiento", se reporta como sospechoso
- **Advertencia**: Si `avance_obra` = 100 pero `estado` â‰  "Terminado", se reporta como inconsistente

**Severidad**: CRÃTICA

### 2. ValidaciÃ³n de Datos NumÃ©ricos en `avance_obra`

Garantiza que `avance_obra` solo maneje datos numÃ©ricos vÃ¡lidos:

- âœ“ Todos los valores deben ser numÃ©ricos (int o float)
- âœ“ No debe haber valores NaN o None
- âœ“ Los valores deben estar en el rango [0, 100]
- âœ“ No debe haber valores negativos

**Severidad**: CRÃTICA

### 3. ValidaciÃ³n de Valores Permitidos en `estado`

Revisa que la variable `estado` solo tome los valores permitidos:

- âœ… "En Alistamiento"
- âœ… "En EjecuciÃ³n"
- âœ… "Terminado"

Cualquier otro valor se reporta como **ERROR CRÃTICO**.

**Severidad**: CRÃTICA

### 4. DetecciÃ³n de Funciones Duplicadas o Intrusas

Revisa el mÃ³dulo de transformaciÃ³n para detectar:

- ğŸ” Funciones con cÃ³digo idÃ©ntico (duplicados exactos)
- ğŸ” Funciones con nombres sospechosamente similares
- ğŸ” MÃºltiples versiones de funciones de normalizaciÃ³n
- ğŸ” Funciones que puedan estar aÃ±adiendo errores o sesgos

**Severidad**: ADVERTENCIA/CRÃTICA

## ğŸš€ Uso

### Uso desde LÃ­nea de Comandos

```bash
# Ejecutar todas las pruebas con un archivo CSV
python test_etl_data_quality.py --data app_outputs/transformed_data.csv

# Especificar mÃ³dulo de transformaciÃ³n a analizar
python test_etl_data_quality.py --data output.csv --module transformation_app/data_transformation_unidades_proyecto.py

# Guardar reporte en ubicaciÃ³n especÃ­fica
python test_etl_data_quality.py --data output.csv --output reports/quality_report.json

# Modo silencioso (menos output)
python test_etl_data_quality.py --data output.csv --quiet
```

### Uso desde CÃ³digo Python

```python
from test_etl_data_quality import ETLDataQualityTester
import pandas as pd

# OpciÃ³n 1: Cargar desde archivo
tester = ETLDataQualityTester(data_path='output.csv')
tester.load_data()
resultados = tester.run_all_tests()

# OpciÃ³n 2: Usar DataFrame existente
df = pd.read_csv('output.csv')
tester = ETLDataQualityTester()
tester.load_data(df)
resultados = tester.run_all_tests()

# Guardar reporte
tester.save_report('quality_report.json')
```

### Ejecutar Tests Individuales

```python
from test_etl_data_quality import ETLDataQualityTester

tester = ETLDataQualityTester()
tester.load_data('output.csv')

# Test 1: Congruencia
resultado_1 = tester.test_estado_avance_consistency()

# Test 2: ValidaciÃ³n numÃ©rica
resultado_2 = tester.test_avance_obra_numeric()

# Test 3: Valores vÃ¡lidos
resultado_3 = tester.test_estado_valid_values()

# Test 4: Funciones duplicadas
resultado_4 = tester.test_duplicate_functions(
    module_path='transformation_app/data_transformation_unidades_proyecto.py'
)
```

## ğŸ“Š InterpretaciÃ³n de Resultados

### CÃ³digos de Salida

- **0**: Todos los tests pasaron âœ…
- **1**: Uno o mÃ¡s tests fallaron âŒ

### Niveles de Severidad

| Nivel       | SÃ­mbolo | DescripciÃ³n                                   |
| ----------- | ------- | --------------------------------------------- |
| **SUCCESS** | âœ“âœ“      | Test pasado exitosamente                      |
| **INFO**    | âœ“       | InformaciÃ³n general                           |
| **WARNING** | âš        | Advertencia - requiere revisiÃ³n               |
| **ERROR**   | âœ—       | Error crÃ­tico - requiere correcciÃ³n inmediata |

### Ejemplo de Output

```
======================================================================
TEST 1: Congruencia entre 'estado' y 'avance_obra'
======================================================================
âœ“ Todos los registros con avance_obra=0 tienen estado='En Alistamiento'
âš  ADVERTENCIA: 5 registros con avance_obra>0 pero estado='En Alistamiento'

âœ“âœ“ TEST 1 PASADO: Estado y avance_obra son congruentes

======================================================================
TEST 2: ValidaciÃ³n de datos numÃ©ricos en 'avance_obra'
======================================================================
âœ“ Todos los valores de 'avance_obra' son numÃ©ricos
âœ“ No hay valores nulos en 'avance_obra'
âœ“ Todos los valores estÃ¡n en el rango [0, 100]
  EstadÃ­sticas: Media=45.32, Mediana=42.50, Min=0.00, Max=100.00

âœ“âœ“ TEST 2 PASADO: avance_obra contiene solo datos numÃ©ricos vÃ¡lidos

======================================================================
RESUMEN DE PRUEBAS DE CALIDAD
======================================================================

Total de pruebas ejecutadas: 4
âœ“ Pruebas pasadas: 4 (100.0%)
âœ— Pruebas falladas: 0 (0.0%)
âš  Advertencias: 2

âœ“ BUENO: Todos los tests pasaron, pero hay advertencias a revisar.
```

## ğŸ“ Estructura del Reporte JSON

El reporte generado tiene la siguiente estructura:

```json
{
  "timestamp": "2025-11-18T10:30:00",
  "total_tests": 4,
  "passed_tests": 4,
  "failed_tests": 0,
  "warnings": 2,
  "details": [
    {
      "test_name": "estado_avance_consistency",
      "passed": true,
      "timestamp": "2025-11-18T10:30:05",
      "total_records": 1500,
      "inconsistencies": [],
      "warnings": [
        {
          "rule": "avance_obra > 0 con estado = 'En Alistamiento' es sospechoso",
          "count": 5,
          "sample_indices": [23, 45, 67, 89, 101]
        }
      ],
      "summary": {
        "zero_avance_count": 150,
        "partial_avance_count": 1200,
        "complete_avance_count": 150,
        "estado_distribution": {
          "En Alistamiento": 150,
          "En EjecuciÃ³n": 1200,
          "Terminado": 150
        },
        "consistency_rate": "100.00%"
      }
    }
  ]
}
```

## ğŸ”§ IntegraciÃ³n con Pipeline ETL

### OpciÃ³n 1: IntegraciÃ³n AutomÃ¡tica

Agregar al final del script de transformaciÃ³n:

```python
from test_etl_data_quality import ETLDataQualityTester

# DespuÃ©s de transformar los datos
df_transformed = transform_data(df_raw)

# Ejecutar pruebas de calidad
tester = ETLDataQualityTester()
tester.load_data(df_transformed)
resultados = tester.run_all_tests()

# Guardar reporte
tester.save_report('app_outputs/reports/quality_report.json')

# Decidir si continuar con el pipeline
if tester.test_results['failed_tests'] > 0:
    raise Exception("Datos no cumplen con estÃ¡ndares de calidad")
else:
    # Continuar con carga a Firebase/S3
    load_to_firebase(df_transformed)
```

### OpciÃ³n 2: Script Independiente

Ejecutar como validaciÃ³n post-transformaciÃ³n:

```bash
# 1. Ejecutar ETL
python pipelines/run_etl.py

# 2. Validar calidad
python test_etl_data_quality.py --data app_outputs/transformed_data.csv

# 3. Si exitoso, continuar con deployment
if [ $? -eq 0 ]; then
    python load_to_firebase.py
else
    echo "ValidaciÃ³n de calidad fallÃ³"
    exit 1
fi
```

## ğŸ“ Ejemplos de Uso

Ver `ejemplo_test_calidad.py` para ejemplos detallados:

1. **Ejemplo BÃ¡sico con Archivo**: Cargar datos desde CSV y ejecutar todas las pruebas
2. **Ejemplo con DataFrame**: Usar DataFrame en memoria
3. **Tests Individuales**: Ejecutar pruebas especÃ­ficas
4. **AnÃ¡lisis de MÃ³dulo**: Analizar funciones del mÃ³dulo de transformaciÃ³n
5. **Pipeline Completo**: Ejemplo de pipeline completo de testing

```bash
# Ejecutar ejemplos
python ejemplo_test_calidad.py
```

## ğŸ¯ Casos de Uso

### Desarrollo

Durante el desarrollo, ejecutar despuÃ©s de cada cambio en el mÃ³dulo de transformaciÃ³n:

```bash
python test_etl_data_quality.py --data test_outputs/sample_data.csv
```

### ProducciÃ³n

Como parte del pipeline de CI/CD o scheduler:

```bash
#!/bin/bash
# Ejecutar ETL
python pipelines/run_etl.py

# Validar calidad
python test_etl_data_quality.py \
    --data app_outputs/transformed_data.csv \
    --output app_outputs/reports/quality_report_$(date +%Y%m%d_%H%M%S).json

# Verificar resultado
if [ $? -eq 0 ]; then
    echo "âœ“ Calidad de datos validada"
    # Continuar con deployment
else
    echo "âœ— ValidaciÃ³n fallÃ³ - revisar reporte"
    exit 1
fi
```

### Debugging

Para diagnosticar problemas especÃ­ficos:

```python
from test_etl_data_quality import ETLDataQualityTester

# Cargar datos problemÃ¡ticos
tester = ETLDataQualityTester(verbose=True)
tester.load_data('problematic_data.csv')

# Ejecutar test especÃ­fico
resultado = tester.test_estado_avance_consistency()

# Analizar inconsistencias
for inconsistency in resultado['inconsistencies']:
    print(f"Regla violada: {inconsistency['rule']}")
    print(f"Ãndices afectados: {inconsistency['sample_indices']}")
```

## ğŸ› ï¸ PersonalizaciÃ³n

### Agregar Nuevos Tests

```python
class ETLDataQualityTester:
    # ... cÃ³digo existente ...

    def test_custom_rule(self) -> Dict[str, Any]:
        """Implementar nueva regla de validaciÃ³n."""
        if self.df is None:
            return {'error': 'No hay datos cargados'}

        results = {'total_records': len(self.df)}

        # Implementar lÃ³gica de validaciÃ³n
        # ...

        # Registrar resultado
        test_passed = True  # o False segÃºn validaciÃ³n
        self._record_test('custom_rule', test_passed, results)

        return results
```

### Modificar Valores Permitidos

```python
# En el script, modificar la constante:
VALID_ESTADO_VALUES = {'En Alistamiento', 'En EjecuciÃ³n', 'Terminado', 'Nuevo Estado'}
```

## ğŸ“š Dependencias

```txt
pandas>=1.3.0
numpy>=1.21.0
```

Instalar con:

```bash
pip install pandas numpy
```

## ğŸ¤ Contribuciones

Para agregar nuevas pruebas o mejoras:

1. Crear nueva funciÃ³n `test_<nombre>()`
2. Seguir el patrÃ³n de las funciones existentes
3. Usar `self._record_test()` para registrar resultados
4. Documentar claramente las reglas de validaciÃ³n

## ğŸ“ Soporte

Para preguntas o problemas:

- Revisar ejemplos en `ejemplo_test_calidad.py`
- Consultar logs detallados con `verbose=True`
- Revisar reportes JSON generados

---

**Ãšltima actualizaciÃ³n**: Noviembre 2025  
**VersiÃ³n**: 1.0.0
